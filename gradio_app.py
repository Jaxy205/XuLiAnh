import gradio as gr
import cv2
import os
import tempfile
from config import Config
from modules import HybridAnomalyDetector
import time

def process_video(video_path, enable_running, enable_falling, enable_gathering, 
                  conf_threshold, flow_threshold, fall_ratio, gather_eps, gather_min_samples):
    """
    H√†m x·ª≠ l√Ω video cho Gradio Interface.
    Ch·∫°y detector tr√™n video ƒë·∫ßu v√†o v√† tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n video k·∫øt qu·∫£.
    """
    if video_path is None:
        return None

    output_filename = f"output_{int(time.time())}.webm"
    output_path = os.path.join(tempfile.gettempdir(), output_filename)

    # C·∫•u h√¨nh h·ªá th·ªëng
    config = Config()
    config.VIDEO_PATH = video_path
    config.OUTPUT_PATH = output_path
    config.ENABLE_RUNNING_DETECTION = enable_running
    config.ENABLE_FALLING_DETECTION = enable_falling
    config.ENABLE_GATHERING_DETECTION = enable_gathering
    config.SAVE_OUTPUT = True
    config.DISPLAY_FPS = False
    
    # C·∫≠p nh·∫≠t tham s·ªë t·ª´ UI
    config.YOLO_CONF_THRESHOLD = conf_threshold
    config.OPTICAL_FLOW_THRESHOLD = flow_threshold
    config.FALL_RATIO_THRESHOLD = fall_ratio
    config.GATHERING_EPS = gather_eps
    config.GATHERING_MIN_SAMPLES = int(gather_min_samples)
    
    detector = HybridAnomalyDetector(config)
    
    # M·ªü video input
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"Kh√¥ng th·ªÉ m·ªü video: {video_path}")

    # L·∫•y th√¥ng s·ªë video
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    fourcc = cv2.VideoWriter_fourcc(*'vp09')
    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    if not writer.isOpened():
        print("Codec vp09 kh√¥ng kh·∫£ d·ª•ng, chuy·ªÉn sang mp4v (.mp4)...")
        # ƒê·ªïi ƒëu√¥i file sang .mp4
        output_filename = f"output_{int(time.time())}.mp4"
        output_path = os.path.join(tempfile.gettempdir(), output_filename)
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    # V√≤ng l·∫∑p x·ª≠ l√Ω
    frame_count = 0
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            annotated_frame, stats = detector.process_frame(frame)
            
            # V·∫Ω th√¥ng tin
            if config.DISPLAY_FPS:
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                current_process_fps = 0
                annotated_frame = detector.visualizer.draw_stats(
                    annotated_frame, frame_count, total_frames, current_process_fps, stats
                )
            
            # Ghi frame v√†o file
            writer.write(annotated_frame)
            
    except Exception as e:
        print(f"L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {str(e)}")
    finally:
        cap.release()
        writer.release()
        
    return output_path

# ƒê·ªãnh nghƒ©a giao di·ªán Gradio
def create_ui():
    with gr.Blocks(title="H·ªá th·ªëng Ph√°t hi·ªán B·∫•t th∆∞·ªùng Video") as demo:
        gr.Markdown("# üé• H·ªá th·ªëng Ph√°t hi·ªán B·∫•t th∆∞·ªùng Video")
        gr.Markdown("T·∫£i l√™n video v√† ch·ªçn c√°c ch·∫ø ƒë·ªô ph√°t hi·ªán mong mu·ªën. K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã tr·ª±c ti·∫øp (streaming).")
        
        with gr.Row():
            with gr.Column():
                input_video = gr.Video(label="Video ƒê·∫ßu v√†o")
                
                gr.Markdown("### C·∫•u h√¨nh Ph√°t hi·ªán")
                cb_running = gr.Checkbox(label="Ph√°t hi·ªán CH·∫†Y (Running)", value=True)
                cb_falling = gr.Checkbox(label="Ph√°t hi·ªán NG√É (Falling)", value=True)
                cb_gathering = gr.Checkbox(label="Ph√°t hi·ªán T·ª§ T·∫¨P (Gathering)", value=True)
                
                gr.Markdown("### Tham s·ªë N√¢ng cao")
                # Kh·ªüi t·∫°o config ƒë·ªÉ l·∫•y gi√° tr·ªã m·∫∑c ƒë·ªãnh
                default_config = Config()
                
                slider_conf = gr.Slider(minimum=0.1, maximum=1.0, value=default_config.YOLO_CONF_THRESHOLD, step=0.05, label="Ng∆∞·ª°ng tin c·∫≠y YOLO")
                slider_flow = gr.Slider(minimum=1.0, maximum=10.0, value=default_config.OPTICAL_FLOW_THRESHOLD, step=0.5, label="Ng∆∞·ª°ng Optical Flow (Ch·∫°y)")
                slider_fall = gr.Slider(minimum=0.5, maximum=3.0, value=default_config.FALL_RATIO_THRESHOLD, step=0.1, label="Ng∆∞·ª°ng t·ª∑ l·ªá khung h√¨nh (Ng√£)")
                slider_eps = gr.Slider(minimum=10, maximum=200, value=default_config.GATHERING_EPS, step=10, label="Kho·∫£ng c√°ch T·ª• t·∫≠p (pixel)")
                slider_samples = gr.Slider(minimum=2, maximum=10, value=default_config.GATHERING_MIN_SAMPLES, step=1, label="S·ªë ng∆∞·ªùi T·ª• t·∫≠p t·ªëi thi·ªÉu")
                
                btn_process = gr.Button("üöÄ B·∫Øt ƒë·∫ßu X·ª≠ l√Ω", variant="primary")
            
            with gr.Column():
                # D√πng Video component ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£
                output_video = gr.Video(label="Video K·∫øt qu·∫£")
        
        btn_process.click(
            fn=process_video,
            inputs=[
                input_video, cb_running, cb_falling, cb_gathering,
                slider_conf, slider_flow, slider_fall, slider_eps, slider_samples
            ],
            outputs=[output_video],
            show_progress=True
        )
        
    return demo

if __name__ == "__main__":
    app = create_ui()
    app.launch(share=False)
